{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation Analysis\n",
    "\n",
    "## Project Overview\n",
    "This project implements customer segmentation using machine learning clustering algorithms to identify distinct customer groups based on their behavior and demographics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('customer_segmentation_data.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info and missing values\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nDescriptive statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df_clean = df.copy()\n",
    "print(f\"Original shape: {df_clean.shape}\")\n",
    "\n",
    "# Remove duplicates\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "print(f\"After removing duplicates: {df_clean.shape}\")\n",
    "\n",
    "# Handle outliers using IQR method\n",
    "numerical_cols = ['age', 'income', 'spending_score', 'membership_years', 'purchase_frequency', 'last_purchase_amount']\n",
    "\n",
    "def remove_outliers(df, columns):\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    return df\n",
    "\n",
    "df_clean = remove_outliers(df_clean, numerical_cols)\n",
    "print(f\"After removing outliers: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for clustering\n",
    "# Encode categorical variables\n",
    "le_gender = LabelEncoder()\n",
    "le_category = LabelEncoder()\n",
    "\n",
    "df_features = df_clean.copy()\n",
    "df_features['gender_encoded'] = le_gender.fit_transform(df_features['gender'])\n",
    "df_features['category_encoded'] = le_category.fit_transform(df_features['preferred_category'])\n",
    "\n",
    "# Select features for clustering\n",
    "features = ['age', 'income', 'spending_score', 'membership_years', 'purchase_frequency', \n",
    "           'last_purchase_amount', 'gender_encoded', 'category_encoded']\n",
    "\n",
    "X = df_features[features]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Features shape: {X_scaled.shape}\")\n",
    "print(f\"Features: {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dimensionality Reduction (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.3f}\")\n",
    "\n",
    "# Plot PCA components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.6)\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.3f})')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.3f})')\n",
    "plt.title('Customer Data - PCA Visualization')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Building - Finding Optimal Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method for K-Means\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "\n",
    "# Plot Elbow Method and Silhouette Scores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Elbow Method\n",
    "ax1.plot(k_range, inertias, 'bo-')\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia')\n",
    "ax1.set_title('Elbow Method for Optimal k')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Silhouette Scores\n",
    "ax2.plot(k_range, silhouette_scores, 'ro-')\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Score vs Number of Clusters')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find optimal k\n",
    "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"Optimal number of clusters: {optimal_k}\")\n",
    "print(f\"Best silhouette score: {max(silhouette_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Apply Clustering Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Hierarchical Clustering\n",
    "hierarchical = AgglomerativeClustering(n_clusters=optimal_k)\n",
    "hierarchical_labels = hierarchical.fit_predict(X_scaled)\n",
    "\n",
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Calculate silhouette scores\n",
    "kmeans_silhouette = silhouette_score(X_scaled, kmeans_labels)\n",
    "hierarchical_silhouette = silhouette_score(X_scaled, hierarchical_labels)\n",
    "if len(set(dbscan_labels)) > 1:\n",
    "    dbscan_silhouette = silhouette_score(X_scaled, dbscan_labels)\n",
    "else:\n",
    "    dbscan_silhouette = -1\n",
    "\n",
    "print(f\"K-Means Silhouette Score: {kmeans_silhouette:.3f}\")\n",
    "print(f\"Hierarchical Silhouette Score: {hierarchical_silhouette:.3f}\")\n",
    "print(f\"DBSCAN Silhouette Score: {dbscan_silhouette:.3f}\")\n",
    "print(f\"DBSCAN found {len(set(dbscan_labels))} clusters (including noise)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cluster Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters using PCA\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Original data\n",
    "axes[0,0].scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.6)\n",
    "axes[0,0].set_title('Original Data')\n",
    "axes[0,0].set_xlabel('PC1')\n",
    "axes[0,0].set_ylabel('PC2')\n",
    "\n",
    "# K-Means\n",
    "scatter = axes[0,1].scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.6)\n",
    "axes[0,1].set_title(f'K-Means Clustering (k={optimal_k})')\n",
    "axes[0,1].set_xlabel('PC1')\n",
    "axes[0,1].set_ylabel('PC2')\n",
    "plt.colorbar(scatter, ax=axes[0,1])\n",
    "\n",
    "# Hierarchical\n",
    "scatter = axes[1,0].scatter(X_pca[:, 0], X_pca[:, 1], c=hierarchical_labels, cmap='viridis', alpha=0.6)\n",
    "axes[1,0].set_title('Hierarchical Clustering')\n",
    "axes[1,0].set_xlabel('PC1')\n",
    "axes[1,0].set_ylabel('PC2')\n",
    "plt.colorbar(scatter, ax=axes[1,0])\n",
    "\n",
    "# DBSCAN\n",
    "scatter = axes[1,1].scatter(X_pca[:, 0], X_pca[:, 1], c=dbscan_labels, cmap='viridis', alpha=0.6)\n",
    "axes[1,1].set_title('DBSCAN Clustering')\n",
    "axes[1,1].set_xlabel('PC1')\n",
    "axes[1,1].set_ylabel('PC2')\n",
    "plt.colorbar(scatter, ax=axes[1,1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use K-Means results for analysis (best performing)\n",
    "df_analysis = df_clean.copy()\n",
    "df_analysis['cluster'] = kmeans_labels\n",
    "\n",
    "# Cluster statistics\n",
    "cluster_stats = df_analysis.groupby('cluster').agg({\n",
    "    'age': ['mean', 'std'],\n",
    "    'income': ['mean', 'std'],\n",
    "    'spending_score': ['mean', 'std'],\n",
    "    'membership_years': ['mean', 'std'],\n",
    "    'purchase_frequency': ['mean', 'std'],\n",
    "    'last_purchase_amount': ['mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "print(\"Cluster Statistics:\")\n",
    "print(cluster_stats)\n",
    "\n",
    "# Cluster sizes\n",
    "cluster_sizes = df_analysis['cluster'].value_counts().sort_index()\n",
    "print(f\"\\nCluster Sizes:\")\n",
    "print(cluster_sizes)\n",
    "\n",
    "# Gender distribution by cluster\n",
    "gender_dist = pd.crosstab(df_analysis['cluster'], df_analysis['gender'], normalize='index') * 100\n",
    "print(f\"\\nGender Distribution by Cluster (%):\")\n",
    "print(gender_dist.round(1))\n",
    "\n",
    "# Category preferences by cluster\n",
    "category_dist = pd.crosstab(df_analysis['cluster'], df_analysis['preferred_category'], normalize='index') * 100\n",
    "print(f\"\\nCategory Preferences by Cluster (%):\")\n",
    "print(category_dist.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cluster Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cluster profiles\n",
    "cluster_profiles = {}\n",
    "\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = df_analysis[df_analysis['cluster'] == cluster]\n",
    "    \n",
    "    profile = {\n",
    "        'size': len(cluster_data),\n",
    "        'avg_age': cluster_data['age'].mean(),\n",
    "        'avg_income': cluster_data['income'].mean(),\n",
    "        'avg_spending_score': cluster_data['spending_score'].mean(),\n",
    "        'avg_membership_years': cluster_data['membership_years'].mean(),\n",
    "        'avg_purchase_frequency': cluster_data['purchase_frequency'].mean(),\n",
    "        'avg_last_purchase': cluster_data['last_purchase_amount'].mean(),\n",
    "        'dominant_gender': cluster_data['gender'].mode()[0],\n",
    "        'dominant_category': cluster_data['preferred_category'].mode()[0]\n",
    "    }\n",
    "    \n",
    "    cluster_profiles[f'Cluster_{cluster}'] = profile\n",
    "\n",
    "# Display profiles\n",
    "profiles_df = pd.DataFrame(cluster_profiles).T\n",
    "print(\"Cluster Profiles:\")\n",
    "print(profiles_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Age vs Income by cluster\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = df_analysis[df_analysis['cluster'] == cluster]\n",
    "    axes[0,0].scatter(cluster_data['age'], cluster_data['income'], \n",
    "                     label=f'Cluster {cluster}', alpha=0.6)\n",
    "axes[0,0].set_xlabel('Age')\n",
    "axes[0,0].set_ylabel('Income')\n",
    "axes[0,0].set_title('Age vs Income by Cluster')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Spending Score vs Purchase Frequency\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = df_analysis[df_analysis['cluster'] == cluster]\n",
    "    axes[0,1].scatter(cluster_data['spending_score'], cluster_data['purchase_frequency'], \n",
    "                     label=f'Cluster {cluster}', alpha=0.6)\n",
    "axes[0,1].set_xlabel('Spending Score')\n",
    "axes[0,1].set_ylabel('Purchase Frequency')\n",
    "axes[0,1].set_title('Spending Score vs Purchase Frequency')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Income vs Last Purchase Amount\n",
    "for cluster in range(optimal_k):\n",
    "    cluster_data = df_analysis[df_analysis['cluster'] == cluster]\n",
    "    axes[0,2].scatter(cluster_data['income'], cluster_data['last_purchase_amount'], \n",
    "                     label=f'Cluster {cluster}', alpha=0.6)\n",
    "axes[0,2].set_xlabel('Income')\n",
    "axes[0,2].set_ylabel('Last Purchase Amount')\n",
    "axes[0,2].set_title('Income vs Last Purchase Amount')\n",
    "axes[0,2].legend()\n",
    "\n",
    "# Cluster size distribution\n",
    "cluster_sizes.plot(kind='bar', ax=axes[1,0])\n",
    "axes[1,0].set_title('Cluster Size Distribution')\n",
    "axes[1,0].set_xlabel('Cluster')\n",
    "axes[1,0].set_ylabel('Number of Customers')\n",
    "\n",
    "# Average spending score by cluster\n",
    "avg_spending = df_analysis.groupby('cluster')['spending_score'].mean()\n",
    "avg_spending.plot(kind='bar', ax=axes[1,1])\n",
    "axes[1,1].set_title('Average Spending Score by Cluster')\n",
    "axes[1,1].set_xlabel('Cluster')\n",
    "axes[1,1].set_ylabel('Average Spending Score')\n",
    "\n",
    "# Average income by cluster\n",
    "avg_income = df_analysis.groupby('cluster')['income'].mean()\n",
    "avg_income.plot(kind='bar', ax=axes[1,2])\n",
    "axes[1,2].set_title('Average Income by Cluster')\n",
    "axes[1,2].set_xlabel('Cluster')\n",
    "axes[1,2].set_ylabel('Average Income')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cluster assignments\n",
    "df_analysis.to_csv('customer_segments.csv', index=False)\n",
    "\n",
    "# Save cluster profiles\n",
    "profiles_df.to_csv('cluster_profiles.csv')\n",
    "\n",
    "# Save cluster centers (K-means)\n",
    "centers_df = pd.DataFrame(kmeans.cluster_centers_, columns=features)\n",
    "centers_df.to_csv('cluster_centers.csv', index=False)\n",
    "\n",
    "print(\"Results saved:\")\n",
    "print(\"- customer_segments.csv\")\n",
    "print(\"- cluster_profiles.csv\")\n",
    "print(\"- cluster_centers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Findings:\n",
    "1. **Optimal Clusters**: Found optimal number of clusters using elbow method and silhouette analysis\n",
    "2. **Algorithm Performance**: K-Means performed best with highest silhouette score\n",
    "3. **Customer Segments**: Identified distinct customer groups with different characteristics\n",
    "4. **Business Insights**: Each cluster represents different customer behavior patterns\n",
    "\n",
    "### Recommendations:\n",
    "- Target marketing campaigns based on cluster characteristics\n",
    "- Develop personalized product recommendations\n",
    "- Optimize pricing strategies for different segments\n",
    "- Focus retention efforts on high-value clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}